{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Producing the data\n",
    "## implement one Apache Kafka producer to simulate the real-time data transfer from one repository to another.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if using pandas to read csv, need to specify dtype=str or need to transform them back to String before sending -> otherwise, pandas would try to infer schema for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Producer Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2256739548.py, line 88)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 88\u001b[0;36m\u001b[0m\n\u001b[0;31m    sleep(5)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka3 import KafkaProducer\n",
    "import random\n",
    "import datetime as dt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pprint as pp\n",
    "from datetime import timedelta\n",
    "import json\n",
    "from json import dumps\n",
    "\n",
    "#configuration\n",
    "#home ip\n",
    "hostip = \"192.168.8.133\"\n",
    "#uni up\n",
    "# hostip = \"118.138.78.178\"\n",
    "\n",
    "def read_file(file):\n",
    "    \"\"\"\n",
    "    Reads a file into a pandas dataframe\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file,encoding='utf-8',dtype=str)\n",
    "    #parse date\n",
    "    df['Date'] = pd.to_datetime(df['Date'],infer_datetime_format=True)\n",
    "    #create mask of year 2011 and sort values\n",
    "    df = (df[df['Date'].dt.year == 2011]\n",
    "          .sort_values(['Date'],\n",
    "                    ascending=[True]))\n",
    "    return df\n",
    "\n",
    "def publish_message(producer_instance, topic_name, data):\n",
    "    try:\n",
    "        producer_instance.send(topic_name, data)\n",
    "        print('Message published successfully. Data: ' + str(data))\n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message.')\n",
    "        print(str(ex))\n",
    "        \n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        _producer = KafkaProducer(bootstrap_servers=[f'{hostip}:9092'],\n",
    "                                  #dumps passes a dictionary into a string\n",
    "                                  #encondes the string as ascii\n",
    "                                  value_serializer=lambda x: dumps(x).encode('ascii'),\n",
    "                                  api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka.')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #setup\n",
    "    topic = 'assignment2b'\n",
    "    file = read_file('data/produce_data.csv')\n",
    "    producer = connect_kafka_producer()\n",
    "    start_date = min(file['Date'])\n",
    "    end_date = max(file['Date'])\n",
    "    delta = timedelta(weeks=1)\n",
    "    print('Publishing records..')\n",
    "    while True:\n",
    "        #if start_date hasn't reached end_date, print test\n",
    "        if start_date <= end_date:\n",
    "            ts =dt.datetime.now().timestamp()\n",
    "            #slide dataframe\n",
    "            data = (file.loc[file['Date']==start_date,:]\n",
    "                    #cast all columns to string\n",
    "                    .astype(str)\n",
    "                    #convert to dictionary\n",
    "                    .to_dict('records'))\n",
    "            #cast date to str.\n",
    "        #else, reset the start_date and continue from the top\n",
    "        else:\n",
    "            start_date = min(file['Date'])\n",
    "            continue\n",
    "        #add one more week to check\n",
    "        start_date += delta\n",
    "        # append data\n",
    "        data = {'ts':ts,'data':data}\n",
    "        #publish message\n",
    "        publish_message(producer,topic,dumps(data))\n",
    "        #sleep\n",
    "        sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
